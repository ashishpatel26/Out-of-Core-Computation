{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is the third of five notebooks documenting a pipelined approach to out-of-core computation using Dask and a Stochastic Gradient Descent classifier available in Scikit-learn. It is purely OPTIONAL, included only for reprocibility and later to show how Dask can handle multiple datasets with ease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.13.0\n",
      "Pandas version: 0.20.1\n"
     ]
    }
   ],
   "source": [
    "items = [(\"NumPy\", np), (\"Pandas\", pd)]\n",
    "for item in items:\n",
    "    print(item[0] + \" version: \" + str(item[1].__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/davidziganto/data/'\n",
    "X = pd.read_hdf(path + 'raw_HIGGS_training_data.h5', key='/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Multiple HDF5 Files (for iterating)\n",
    "Again, update the **path** variable if you want to store this locally. Everything else is fine to leave as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "num_files = 5\n",
    "split_value = int(X.shape[0]/num_files)\n",
    "path = '/Users/davidziganto/data/for_iterating/raw_HIGGS_training_data_'\n",
    "\n",
    "# Split single file into multiple HDF5 files\n",
    "start, stop = 0, split_value\n",
    "groupkey = ['zero', 'one', 'two', 'three', 'four']\n",
    "for i in range(int(X.shape[0]/split_value)):\n",
    "    filename = path + str(i) + '.h5'\n",
    "    X.iloc[start:stop].to_hdf(filename, \n",
    "                              format='table', \n",
    "                              key='/' + groupkey[i], \n",
    "                              mode='w',\n",
    "                              append=False, \n",
    "                              complevel=9, \n",
    "                              complib='blosc',\n",
    "                              fletcher32=True)\n",
    "    start += split_value\n",
    "    stop += split_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
