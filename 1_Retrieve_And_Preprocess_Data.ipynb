{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken directly from the [UCI Machine Learning Repo](https://archive.ics.uci.edu/ml/datasets/HIGGS):\n",
    ">The data has been produced using Monte Carlo simulations. The first 21 features (columns 2-22) are kinematic properties measured by the particle detectors in the accelerator. The last seven features are functions of the first 21 features; these are high-level features derived by physicists to help discriminate between the two classes. There is an interest in using deep learning methods to obviate the need for physicists to manually develop such features. Benchmark results using Bayesian Decision Trees from a standard physics package and 5-layer neural networks are presented in the original paper. The last 500,000 examples are used as a test set.\n",
    "\n",
    "Attribute info:\n",
    ">The first column is the **class label**\n",
    ">  * 1 for signal \n",
    ">  * 0 for background\n",
    ">\n",
    "> The following 28 columns are **features** (21 low-level features then 7 high-level features):\n",
    ">   * lepton pT \n",
    ">   * lepton eta \n",
    ">   * lepton phi\n",
    ">   * missing energy magnitude\n",
    ">   * missing energy phi \n",
    ">   * jet 1 pt \n",
    ">   * jet 1 eta \n",
    ">   * jet 1 phi \n",
    ">   * jet 1 b-tag \n",
    ">   * jet 2 pt \n",
    ">   * jet 2 eta \n",
    ">   * jet 2 phi \n",
    ">   * jet 2 b-tag \n",
    ">   * jet 3 pt \n",
    ">   * jet 3 eta \n",
    ">   * jet 3 phi \n",
    ">   * jet 3 b-tag \n",
    ">   * jet 4 pt \n",
    ">   * jet 4 eta \n",
    ">   * jet 4 phi \n",
    ">   * jet 4 b-tag \n",
    ">   * m_jj \n",
    ">   * m_jjj \n",
    ">   * m_lv \n",
    ">   * m_jlv \n",
    ">   * m_bb \n",
    ">   * m_wbb \n",
    ">   * m_wwbb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versions\n",
    "The code in this notebook runs with Python 3.5. You may encounter issues if you run it with another version, especially Python 2.x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 0.20.1\n"
     ]
    }
   ],
   "source": [
    "print('Pandas version:', pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = (\"label\",\n",
    "           \"lepton_pT\",\n",
    "           \"lepton_eta\", \n",
    "           \"lepton_phi\", \n",
    "           \"missing_energy_magnitude\", \n",
    "           \"missing_energy_phi\",\n",
    "           \"jet_1_pt\",\n",
    "           \"jet_1_eta\",\n",
    "           \"jet_1_phi\",\n",
    "           \"jet_1_b_tag\",\n",
    "           \"jet_2_pt\",\n",
    "           \"jet_2_eta\",\n",
    "           \"jet_2_phi\",\n",
    "           \"jet_2_b_tag\",\n",
    "           \"jet_3_pt\",\n",
    "           \"jet_3_eta\",\n",
    "           \"jet_3_phi\",\n",
    "           \"jet_3_b_tag\",\n",
    "           \"jet_4_pt\",\n",
    "           \"jet_4_eta\",\n",
    "           \"jet_4_phi\",\n",
    "           \"jet_4_b_tag\",\n",
    "           \"m_jj\",\n",
    "           \"m_jjj\",\n",
    "           \"m_lv\",\n",
    "           \"m_jlv\",\n",
    "           \"m_bb\",\n",
    "           \"m_wbb\",\n",
    "           \"m_wwbb\")\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00280/HIGGS.csv.gz\"\n",
    "\n",
    "raw_data = pd.read_csv(url, header=None, names=columns, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to HDF5 w/Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/davidziganto/data/'\n",
    "raw_data.to_hdf(path + 'raw_HIGGS_data.h5', \n",
    "                format='table',\n",
    "                key='/a',\n",
    "                mode='w',\n",
    "                append=False, \n",
    "                complevel=9, \n",
    "                complib='blosc',\n",
    "                fletcher32=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading and unzipping the HIGGS gzip file creates a 8.04 GB CSV file. Writing that data to HDF5 with Blosc compression set to the max level results in a 2.14 GB H5 file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
